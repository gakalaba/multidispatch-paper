\section{Correctness Proof}
\label{sec:correctness}
We consider an arbitrary, well-formed execution $\alpha$ of a set of application processes interacting with an \sys{} service. We define $e_1 <_p e_2$ to mean that $e_1$ and $e_2$ were issued by the same client, and $e_1$ was invoked before $e_2$ by that client, or $\text{inv}(e_1) < \text{inv}(e_2)$; we say that $e_1$ is the \textit{predecessor} request to $e_2$, and $e_2$ is the \textit{successor} request to $e_1$. We also define $e_3 \rightarrow e_4$ to mean $e_3$ precedes $e_4$ in real time, or $\text{resp}(e_3) < \text{inv}(e_4)$. To reason about the order of operations in \sys{}, we define several terms:

Given an operation $e$, we define it as \textit{committed} once a quorum of replicas of the relevant shard added it to their buffered log. We define it as \textit{ordered} once a quorum of replicas have added it to their ordered log. We define it as \textit{coordinated} once the leader has received a coordination timestamp from the predecessor request.

Finally, the sequential specification $\mathcal{G}_x$ of an object $x \in X$ is the set of all sequences of invocation-response pairs of reads and writes to $x \in X$ such that each read returns the value written by the most recent write.

Recall that each operation in \sys{} is assigned a unique timestamp, $\epsilon$, once it is \textit{committed} and \textit{coordinated} by its \textit{predecessor}. Using these observations, we can define a total order over the operations to a single object $x \in X$, $<_x$ at each shard.

\begin{lem}
    \label{lemmaD8}
    The sequence $S_x$ defined by $<_x$ over the invocation-response pairs of complete operations to object $x \in X$ is in the sequential specification $\mathcal{G}_x$.
\end{lem}
\begin{proof}
    Each operation, $e$, is assigned a preliminary unique timestamp, $\epsilon$, once it is \textit{committed} and \textit{coordinated} by its \textit{predecessor}, $e_{pred}$, or if $e$ doesn't have a \textit{predecessor}, $\epsilon$ is assigned upon arrival and persisted among replicas when $e$ is \textit{ordered}. This timestamp might change only if the shard fails, after which $e$ will be assigned a new timestamp $\epsilon'$ by the failover procedure.
    
    Timestamps are assigned (normally and during failover) as $\epsilon = \max(\epsilon_\text{pred}+1, shard\_ts)$, where $\epsilon_\text{pred}$ is the timestamp of the \textit{predecessor} received via \textit{coordination} and $shard\_ts$ is the shard's own local timestamp at the time of assignment. Before any operations are added to the shard's execution log, the initial value of the shard's local timestamp is $0$; during failover, the initial value is the timestamp of the last \textit{ordered} operation's plus 1. Importantly, between assigning every timestamp, the shard updates its own local timestamp as $shard\_ts = \epsilon + 1$. After an operation is assigned a timestamp, it is added to the ordered log and replicated at this index with this timestamp, constructing $<_x$.

    Since each $\epsilon$ is at least as large as $shard\_ts$ at the time of assignment, and $shard\_ts$ strictly increases between each timestamp assignment, all $\epsilon$ within a shard are unique and also strictly increase.

    Finally, all replicas will apply operations to the state machine from the ordered log in timestamp order. Since $S_x$ is the sequence of invocation-response pairs defined by $<_x$, it is in the object's sequential specification.
\end{proof}

% \begin{lem}
%     \label{lemmagetpred}
%     $\texttt{getPredecessor}(e)$ is guaranteed to eventually return.
% \end{lem}

% \begin{proof}
%     If $e$ does not have a \textit{predecessor}, or the \textit{predecessor} is at the same shard as $e$, then by line \ref{neginfy} of algorithm \ref{failover}, it will be assigned a value of $-\infty$ immediately.

%     Otherwise, it will invoke \texttt{getPredecessor}. 

%     Otherwise, the \textit{predecessor} is at a separate shard. If the shard does not experience any failures, the \textit{predecessor} will eventually be assigned a timestamp and the shard will respond with a value to the call. 
    
%     If the shard of the \textit{predecessor} experiences failover, it will also eventually make calls to \texttt{getPredecessor} and \texttt{getSuccessor}. The calls to \texttt{getSuccessor} are always guaranteed to return and never block, as in algorithm \ref{failover}. The call to \texttt{getPredecessor}(\textit{predecessor}) will eventually hit a \textit{predecessor} operation that has no \textit{predecessor} and returns immediately, and using this return value and the value returned from the call to \texttt{getSuccessor} can complete failover. After this it can send a timestamp to the pending call to $\texttt{getPredecessor}(e)$.
% \end{proof}

% \begin{thm}[Hall's theorem]
%     \label{Hall}
%     $\mathcal{G}$ has a matching of size $|\mathcal{A}|$ if and only if for every $\mathcal{S} \subseteq \mathcal{A}$ we have $|N(\mathcal{S})|\geq|\mathcal{S}|$, where $N(\mathcal{S}) = {b \in \mathcal{B}: \; \exists a \in \mathcal{S} \; \text{with} \; (a, b) \in \mathcal{E}}$.
% \end{thm}

% \begin{lem}
%     \label{failover_converges}
%     The failover protocol always converges.
% \end{lem}

% \begin{proof}
%     The failover protocol uses the Ford-Fulkerson algorithm to find a matching over the bipartite graph, $\mathcal{G}$, of committed-but-not-ordered operations and their timestamp candidates. To show this procedure converges, we must show that there exists at least one matching over $\mathcal{G}$, which we show by applying Hall's Theorem.

%     To prove this, first we construct $\mathcal{G'}$, the bipartite graph of committed-but-not-ordered operations and their initial timestamp assignments \textit{prior} to failover. We construct $\mathcal{A'}$ as all the committed-but-not-ordered operations that prior to failover have externalized their initial timestamp assignments to their \textit{successors}, who have in turn calculated their own timestamps and been added to the ordered log, and possibly externalized those timestamps to their respective \textit{successors}. We construct $\mathcal{B'}$ as the set of all initial timestamp assignments for each operation in $\mathcal{A'}$, and we add an edge between each vertex in $\mathcal{A'}$ and its assigned timestamp in $\mathcal{B'}$.

%     Prior to failure, timestamp assignment completes as described by lines \ref{ts_assignment_pt1} and \ref{ts_assignment_pt2} in algorithm \ref{shardprotocolcoord}. Because the shard timestamp strictly increases between each assignment and because each assignment is at least as large as the shard timestamp, the initial timestamps across operations strictly increase in the committed-but-not-ordered log order. Importantly, this implies all the initial timestamps are unique and that $|\mathcal{B'}| = |\mathcal{A'}|$ and $\forall a' \in \mathcal{A'}, N(a') = 1$. Because of this, it must be the case $\forall S \subseteq \mathcal{A'}: |N(S)| = |S|$. By Hall's theorem then, we know $\mathcal{G'}$ contains a perfect matching of size $|\mathcal{A'}|$.

%     Finally, we construct the bipartite graph, $\mathcal{G}$, as follows:

%     We create a set, $\mathcal{A}$ of vertices for each committed-but-not-ordered operation that has finite return values from \texttt{getSuccessor}. We then create an infinite set of vertices representing all the integers. Lastly, we construct our edge set $\mathcal{E}$: for each operation in $\mathcal{A}$, we add an edge between itself and each integer that is in the range strictly greater than the value returned from \texttt{getPredecessor} and strictly less than the value returned from \texttt{getSuccessor}. Denote the subset of integers that have an edge incident to them from at least one vertex in $\mathcal{A}$ as $\mathcal{B}$, and this set represents timestamp candidates for each committed-but-not-ordered operation.

%     To show there exists a matching for each operation in $\mathcal{A}$, we first show that (1) $\mathcal{A} = \mathcal{A'}$ and we show that (2) $\forall a \in \mathcal{A}: N_{\mathcal{G}}(a) \supseteq N_{\mathcal{G'}}(a)$:
    
%     (1) It is easy to show $\mathcal{A} = \mathcal{A'}$ since by construction, $\mathcal{A'}$ contains all the operations that during failover will receive finite values from \texttt{getSuccessor}. 

%     (2) As shown above, $\forall a \in \mathcal{A}, N_{\mathcal{G'}}(a) = 1$, which is the unique timestamp assigned prior to failure. By the assignment process \ref{ts_assignment_pt1}, this timestamp $N_{\mathcal{G'}}(a)$ is strictly larger than the operation $a$'s \textit{predecessor}. Further, by construction, $N_{\mathcal{G}}(a)$ contains all integer values strictly larger than the \textit{predecessor} and strictly less than \textit{successor}, therefore it must at least contain $N_{\mathcal{G'}}(a)$ and potentially other candidates in the range.

%     Since $\mathcal{A} = \mathcal{A'}$ and $\forall a \in \mathcal{A}, a' \in \mathcal{A'}: N(a) \supseteq N(a')$, we have $\forall S \subseteq \mathcal{A}: |N_{\mathcal{G}}(S)| \geq |N_{\mathcal{G'}}(S)| = |S|$. Therefore, by Hall's theorem \ref{Hall}, $\mathcal{G'}$ contains a perfect matching and the failover protocol converges.
% \end{proof}


\begin{lem}
\label{lemma1}
Consider a pair of operations $e_1, e_2$ such that $e_1 <_p e_2$, and further assume each operation is committed, coordinated, and been assigned timestamp $\varepsilon_1, \varepsilon_2$, at their respective shards. Then $\varepsilon_1 < \varepsilon_2$.
\end{lem}
\begin{proof}
We case upon the presence of shard leader failures:

\wl{We "case"?}

\noindentparagraph{Case 1.} \textit{No failures}.
Let $e_1$ and $e_2$ be two operations such that $e_1 <_p e_2$.
Consider the timestamp assignment process for $e_1$ and $e_2$. Let $\epsilon_1$ and $\epsilon_2$ be the timestamps assigned to $e_1$ and $e_2$, respectively.

Since $e_1 <_p e_2$, $e_2$ sends a coordination request to $e_1$. Upon receiving the coordination request, $e_1$ responds with its timestamp $\epsilon_1$, which it cannot send until it is committed and coordinated. Consequently, upon receiving $\epsilon_1$, $e_2$ sets its timestamp $\epsilon_2 = \max(\epsilon_1 + 1, \epsilon_{\text{shard}2})$.

This implies $\epsilon_2 \geq \epsilon_1 + 1$, or $\epsilon_1 < \epsilon_2$.

\noindentparagraph{Case 2.} \textit{With failures}.
We case upon which shard fails.

\noindentparagraph{Subcase A.} \textit{Operations $e_1$ and $e_2$ are at separate shards. Shard with $e_1$ fails after $e_1$ is \textit{committed}, before it is \textit{ordered}. Shard with $e_2$ does not fail.}

Assume shard with $e_1$ fails.

During failover, all committed-but-not-ordered entries, including $e_1$, are processed and assigned new timestamps. Specifically, the new shard leader will call \texttt{getTimestampChain} for all committed-but-not-ordered entries, including $e_1$.

If $e_1$ had been assigned a timestamp prior to failure and coordinated $e_2$ (or some \textit{predecessor} chain ending with $e_2$), then since we know the shard with $e_2$ does not fail, \texttt{getTimestampChain} will return a non-NULL value reflecting the timestamp\_chain of $e_2$ (or some operation invoked after $e_1$ and before $e_2$. Importantly, this timestamp\_chain will include the timestamp initially assigned to $e_1$ prior to failure, which the new shard leader will assign as $e_1$'s new timestamp during failure upon the return of \texttt{getTimestampChain}. As shown in Case 1, the timestamps assigned prior to failure abide by $e_1 <_p e_2 \implies \epsilon_1 < \epsilon_2$.

If $e_1$ had not been assigned a timestamp prior to failure, or if $e_1$ had been assigned a timestamp prior to failure but had never coordinated $e_2$ (or some \textit{predecessor} chain ending with $e_2$), then \texttt{getTimestampChain} will return a NULL value. Importantly, $e_1$ will then be assigned a newly calculated timestamp according to lines \ref{B_begin} to \ref{B_end} of the failover protocol \ref{failover}.

Since $e_2$ had not received $e_1$'s old timestamp prior to failure, this new timestamp, $\epsilon_1$, will trivially be strictly less than $\epsilon_2$. As shown in Case 1, during non-failover mode $\epsilon_2$ will be strictly larger than $\epsilon_1$ for any value assigned to $\epsilon_1$ during failover that is sent to the shard with $e_2$ once failover completes.

\noindentparagraph{Subcase B.} \textit{Operations $e_1$ and $e_2$ are at separate shards. Shard with $e_2$ fails after $e_2$ is \textit{committed}, before it is \textit{ordered}. Shard with $e_1$ does not fail.}

Assume shard with $e_2$ fails.

During failover, all committed-but-not-ordered entries, including $e_2$, are processed and assigned new timestamps. Specifically, the new shard leader will call \texttt{getTimestampChain} for all committed-but-not-ordered entries, including $e_2$.

If $e_2$ had been assigned a timestamp prior to failure and coordinated some \textit{successor}, then \texttt{getTimestampChain} will return a non-NULL value reflecting a timestamp\_chain including the timestamp initially assigned to $e_2$ prior to failure, which the new shard leader will assign as $e_2$'s new timestamp during failure upon the return of \texttt{getTimestampChain}. As shown in Case 1, the timestamps assigned prior to failure abide by $e_1 <_p e_2 \implies \epsilon_1 < \epsilon_2$.

Otherwise, if $e_2$ didn't coordinate a \textit{successor}, then \texttt{getTimestampChain} will return a NULL value. Importantly, $e_1$ will then be assigned a newly calculated timestamp according to lines \ref{B_begin} to \ref{B_end} of the failover protocol \ref{failover}. Trivially, this new timestamp $\epsilon_2$ is strictly larger than $\epsilon_1$, since a call to \texttt{getPredecessorTS} is made and the new timestamp assigned is strictly larger than the predecessor timestamp.
% didn't coordinate successor/didn't have successor/was never assigned

\noindentparagraph{Subcase C.} \textit{Operations $e_1$ and $e_2$ are at the same shard. That shard with both $e_1$ and $e_2$ fails after $e_1$ and $e_2$ are both \textit{committed}, before they are \textit{ordered}.}

Assume shard with $e_1$ and $e_2$ fails.

During failover, the new shard leader will call \texttt{getTimestampChain} for all committed-but-not-ordered entries, including $e_1$ and $e_2$.

Since $e_1$ was invoked before $e_2$, if it had been assigned an old timestamp that was externalized, that value would be contained in a timestamp chain returned from a call made to \texttt{getTimestampChain} on behalf of both $e_1$ and $e_2$, and as shown in the non-failure case, $\epsilon_1 < \epsilon_2$. 

Otherwise, if both $e_1$ and $e_2$ receive NULL values from \texttt{getTimestampChain}, then $e_1$ will be processed before $e_2$ since entries are grouped by client PIDs and processed in sequence number order (lines \ref{B_begin} - \ref{B_end} of \ref{failover}. Thus when $e_2$ makes a call to \texttt{getPredecessorTS}, it will read the already assigned $\epsilon_1$ and pick an $\epsilon_2$ that is strictly larger.

\noindentparagraph{Subcase D.} \textit{Operations $e_1$ and $e_2$ are at separate shards. Both shards with $e_1$ and $e_2$, respectively, fail after $e_1$ and $e_2$ are \textit{committed}, before each is \textit{ordered}.}

Assume the shard with $e_1$ and the shard with $e_2$ both fail.

During failover, the new shard leaders will call \texttt{getTimestampChain} for all committed-but-not-ordered entries, including $e_1$ and $e_2$.

Just like in Subcase C, since $e_1$ was invoked before $e_2$, if it had been assigned an old timestamp that was externalized, that value would be contained in a timestamp chain returned from a call made to \texttt{getTimestampChain} on behalf of both $e_1$ and $e_2$, and as shown in the non-failure case, $\epsilon_1 < \epsilon_2$. 

Lastly, if both $e_1$ and $e_2$ receive NULL values from \texttt{getTimestampChain}, then $e_1$ will be processed before $e_2$, since its call to \texttt{getPredecessorTS} will return immediately and $e_2$'s will block until an $\epsilon_1$ is assigned at the respective shard. Finally, $\epsilon_2$ will be trivially larger than $\epsilon_1$ since it will be assigned a value strictly larger than the value returned from \texttt{getPredecessorTS}.

% Version with bipartite graph
% The failover protocol uses the Ford-Fulkerson algorithm to find a matching over the bipartite graph, $\mathcal{G}$, of committed-but-not-ordered operations and their timestamp candidates. By lemma \ref{failover_converges}, this procedure converges. Since the set of candidate timestamps in the bipartite graph only contains unique candidates, the matching constructed assigns unique timestamps to all operations during failover. Furthermore, by construction, the candidate timestamps for each committed-but-not-ordered operation are within a range that is strictly larger than the operation's \textit{predecessor} and strictly less than the operation's \textit{successor}, thus the matching constructed will pick a new timestamp that is strictly larger than the \textit{predecessor} and strictly less than the \textit{successor}. Therefore  $e_1 <_p e_2 \implies \epsilon_1 < \epsilon_2$.


% Version with sorting by successor
% We case upon which shard fails.

% \noindentparagraph{Subcase A.} \textit{Operations $e_1$ and $e_2$ are at separate shards. Shard with $e_2$ fails after $e_2$ is \textit{committed}, before it is \textit{ordered}. Shard with $e_1$ does not fail.}

% Assume shard with $e_2$ fails.

% During failover, all committed-but-not-ordered entries, including $e_2$, are processed and assigned new timestamps. Specifically, each entry gets a predecessor and successor timestamp via calls made to \texttt{getPredecessor} and \texttt{getSuccessor}, respectively, and the new shard leader sorts all committed-but-not-ordered entries by successor timestamp. Let $\epsilon_1$ and $\epsilon_2$ be the timestamps assigned to $e_1$ and $e_2$, respectively, where $\epsilon_1$ was never recalculated since the shard never failed.

% By the failover protocol, $\epsilon_2 = \max(\epsilon_1 + 1, \epsilon_{\text{shard}2}) \geq \epsilon_1 + 1$, ensuring $\epsilon_1 < \epsilon_2$.

% \noindentparagraph{Subcase B.} \textit{Operations $e_1$ and $e_2$ are at separate shards. Shard with $e_1$ fails after $e_1$ is \textit{committed}, before it is \textit{ordered}. Shard with $e_2$ does not fail.}.

% Assume shard with $e_1$ fails.

% By the failover protocol, the new shard leader will call \texttt{getPredecessor} and \texttt{getSuccessor} for all committed-but-not-ordered entries, including $e_1$, giving them a predecessor and successor timestamp, respectively, then it will sort them based on successor timestamp, and finally in sorted order assign them new timestamps. Importantly, \texttt{getSuccessor} will return since the shard with operation $e_2$ hasn't failed. Similarly, it is guaranteed that \texttt{getPredecessor} will return by lemma \ref{lemmagetpred}.

% We prove by induction that during failover, for all timestamps assigned to the sorted set of committed-but-not-ordered entries, $\epsilon_i \leq \epsilon_i\_\text{succ}$.

% \textbf{Base Case:} Consider the timestamp, $\epsilon_0$, assigned to the first processed entry, $e_0$, in the sorted set of committed-but-not-ordered entries.  $\epsilon_0 < \epsilon_0\_\text{succ}$
% \\
% When the new leader processes the 0th committed-but-not-ordered entry during failover, it will assign it a timestamp of
% $$\epsilon_0 = \max(\epsilon_0\_\text{pred} + 1, shard\_ts_0)$$
% If $\epsilon_0 = \epsilon_0\_pred + 1$, we know this is at most the value it used to coordinate its successor prior to failure, and that successor must have assigned itself a timestamp strictly larger than this sent value. Thus, $\epsilon_0 \leq \epsilon_0\_\text{succ}$

% Else $\epsilon_0 = shard\_ts_0$.
% Let's call the last ordered entry in the ordered log at the start of failover $e_k$. The initial value of the shard timestamp, $\text{shard\_ts}_0$, assigned at the beginning of recovery is the timestamp of the last ordered entry, $\epsilon_k + 1$. 

% It is possible that any of the committed-but-not-ordered entries had been assigned a timestamp prior to failover that was sent to a successor. We know all of these assigned timestamps must have been strictly larger than $\epsilon_k$, or at least as large as $shard\_ts_0$. And since during coordination, successors assign themselves strictly increasing timestamps, we also know the timestamps of any successors to entries after $e_k$ had timestamps strictly greater than $shard\_ts_0$.

% Therefore, $\epsilon_0 \leq \epsilon_{0\_\text{succ}}$.


% \textbf{Inductive Step:} Assume that the claim holds for some positive integer $i$. That is, consider the timestamp, $\epsilon_i$, assigned to some committed-but-not-ordered entry processed in the sorted order during failover, $e_i$, then $\epsilon_i \leq \epsilon_i\_\text{succ}$.

% Now, we want to show that the claim also holds for $i+1$, i.e., we want to show $\epsilon_{i+1} \leq \epsilon_{i+1}\_\text{succ}$.

% When the new leader processes committed-but-not-ordered entry $e_{i+1}$ during failover, it will assign it a timestamp of
% $$\epsilon_{i+1} = \max(\epsilon_{i+1}\_\text{pred} + 1, shard\_ts_{i+1})$$
% If $\epsilon_{i+1} = \epsilon_{i+1}\_\text{pred} + 1$, we know this is at most the value it used to coordinate its successor prior to failure, and that successor must have assigned itself a timestamp strictly larger than this sent value. Thus $\epsilon_{i+1} \leq \epsilon_{i+1}\_\text{succ}$.

% Else $\epsilon_{i+1} = shard\_ts_{i+1}$. Between assigning every committed-but-not-ordered entry, the shard updates its timestamp to be the last timestamp assigned to an entry plus one, or $shard\_ts_{i+1} = \epsilon_i + 1$. Moreover, we know that $\epsilon_{i}\_\text{succ} \leq \epsilon_{i+1}\_\text{succ}$ due to sorted order by successor timestamps. Using our inductive hypothesis, we know $\epsilon_i \leq \epsilon_i\_\text{succ}$ or $\epsilon_i + 1 \leq \epsilon_i\_\text{succ}+1$. From all of this we can show,

% $$\epsilon_{i+1} = shard\_ts_{i+1} = \epsilon_i + 1 \leq \epsilon_i\_\text{succ} + 1 \leq \epsilon_{i+1}\_\text{succ}$$.

% \noindentparagraph{Subcase C.} \textit{Both shards with $e_1$ and $e_2$ fail after $e_1$ and $e_2$ are \textit{committed}, before each is \textit{ordered}. $e_1$ and $e_2$ could be at separate shards or the same shard.}

% Assume both shards fail. Let's denote the shard with operation $e_1$ as $Shard_1$ and the shard with $e_2$ as $Shard_2$.

% By the failover protocol, the new shard leaders at both shards will call \texttt{getPredecessor} and \texttt{getSuccessor} for all committed-but-not-ordered entries. When $Shard_1$'s new leader invokes \texttt{getSuccessor}, $Shard_2$ will respond with its return value from invoking \texttt{getSuccessor} minus 1, $\epsilon_2\_\text{succ} - 1$, as by line \ref{mytsminus1} in algorithm \ref{failover}. When $Shard_2$'s new leader invokes \texttt{getPredecessor}, $Shard_1$ will block until it has completed the failover procedure and assigned (and persisted) a final timestamp for $e_1$. 

% By the reasoning in subcase B, $\epsilon_1 \leq \epsilon_2\_\text{succ} - 1$. Thus $Shard_2$'s new leader will receive a \textit{predecessor} timestamp for $e_2$ such that $\epsilon_2\_\text{pred} < \epsilon_2\_\text{succ}$ when \texttt{getPredecessor} finally returns. As in subcase A, $\epsilon_2 = \max(\epsilon_2\_\text{pred}+1, \epsilon_{shard2})$.

% If $\epsilon_2 = \epsilon_2\_\text{pred}+1$ then since $\epsilon_2\_\text{pred} < \epsilon_2\_\text{succ}$, it follows $\epsilon_2 \leq \epsilon_2\_\text{succ}$.

% Else $\epsilon_2 = \epsilon_{shard2}$. By similar inductive reasoning as in case B, it follows that $\epsilon_2 \leq \epsilon_2\_\text{succ}$.
\end{proof}

\begin{lem}
\label{lemma2}
Consider a pair of operations on the same shard $e_1, e_2$ such that $e_1 <_x e_2$, and further assume each operation is committed, coordinated, and been assigned timestamp $\varepsilon_1, \varepsilon_2$ at their shard. Then $\varepsilon_1 < \varepsilon_2$.
\end{lem}
\begin{proof}
We case upon the presence of shard leader failures:

\noindentparagraph{Case 1.} \textit{No failures}.
A shard leader assigns a timestamp to a committed and coordinated entry as 
$\epsilon = \max(\epsilon_{\text{pred}} + 1, \epsilon_{\text{shard}})$ and immediately afterwards updates its own value to be 
$\epsilon_{\text{shard}} = \epsilon + 1$
Therefore, if $e_1$ is ordered in the shard log before $e_2$, and entries can only be added to the log once they are committed and coordinated, 
$\epsilon_2 >= \epsilon_{\text{shard}} \geq \epsilon_1 + 1$ or
$\epsilon_1 < \epsilon_2$

\noindentparagraph{Case 2.} \textit{With failures}.
The failover procedure splits the entries it has to order into 2 sets - the first set contains entries that can obtain their previously assigned timestamps and the second set contains entries that cannot and hence are assigned new timestamps. By Case 1, we know that the first set will recycle old timestamps that were unique, and they will be added in a sorted order to the log, thus the lemma holds trivially.

We use similar reasoning to Case 1 for showing this lemma holds over entries in the second set. First, the shard timestamp is incremented after assigning the last entry from the first set, thus it is strictly larger than all timestamps from the first set. Lastly, as in Case 1, each entry will be assigned a timestamp that is at least as large as the shard timestamp, and since this timestamp is strictly increasing between all the assignments, it must be the case that $\epsilon_1 < \epsilon_2$.

% The failover protocol uses the Ford-Fulkerson algorithm to find a matching over the bipartite graph, $\mathcal{G}$, of committed-but-not-ordered operations and their timestamp candidates. By lemma \ref{failover_converges}, this procedure converges. Since the set of candidate timestamps in the bipartite graph only contains unique candidates, the matching constructed assigns unique timestamps to all operations during failover. Afterwards, since these operations are sorted by timestamp, it follows that $e_1 <_x e_2 \implies \epsilon_1 < \epsilon_2$.


% By line XXX, a shard adds an operation to the log after it is committed and coordinated. By line XXX, when $e_1$ is committed and coordinated, the shard assigns a timestamp for the entry with value $\varepsilon_1$, adds $e_1$ to its ordered log, and update its shard timestamp to be $\varepsilon_{\textit{shard}} = \max(\varepsilon_1, \varepsilon_{\textit{shard}}) + 1$. Because of this, any operation ordered in the log after $e_1$ is assigned a timestamp
%  $\varepsilon_2 = \max(\varepsilon_{\textit{pred}}+1, \varepsilon_{\textit{shard}})$.
% It follows that $\varepsilon_1 < \varepsilon_2$.

%Algorithms~\ref{clientprotocol}, ~\ref{shardprotocolmessages},and~\ref{shardprotocolmessages}
% All operations must send coordination requests to their predecessors, by line 11 of Algorithm~\ref{clientprotocol}. When $e_1$ receives the coordination request sent by the client for $e_2$, $e_1$ cannot respond until it is committed and coordinated, by line 9 of Algorithm~\ref{shardprotocolcoord}.

% By 
% When a request is committed and coordinated, it sets its timestamp ε = max(εpred+1, εshard).
% When a request sends a response to a coordination request, it send ε, by line XXX. Thus e1 will send ε1 to e2, where ε1 = max(ε1pred+1, εshard1).
% When e2 receives a response to its coordination request from e1, it will set its timestamp ε2 = max(ε1+1, εshard2).
% Trivially, ε1 < ε2 = max(ε1+1, εshard2)

\end{proof}

\begin{lem}
\label{lemma3}
Consider a sequence of operations $e_1,...,e_n$ such that the following hold: (0) n > 2(1) successive pairs alternate between belonging to $<_p$ and $<_x$, making no assumption about which edge type is first; (2) the last pair belongs to $\rightarrow$; and (3) $e_1$ and $e_n$ are at the same shard, $X$. Further assume each operation is committed, coordinated, and been assigned timestamp $\varepsilon_1, ..., \varepsilon_n$ at their respective shards. Then $\varepsilon_1 < \varepsilon_n$.
\end{lem}

\begin{proof}
We case upon the presence of shard leader failures:

\noindentparagraph{Case 1.} \textit{No failures}.
By Lemmas \ref{lemma1} and \ref{lemma2}, we know that $\epsilon_1 < \epsilon_{n-1}$. We also know $e_{n-1}$ can't execute until it is \textit{committed} and \textit{coordinated}, which must happen after $e_1$ is \textit{committed} and \textit{coordinated}. If there is a real-time edge between $e_{n-1}$ and $e_n$, and $e_{n-1}$ cannot return to its client until it is \textit{committed} and \textit{coordinated}, then we know $e_{n-1}$ is \textit{committed} and \textit{coordinated} before $e_n$ arrives at shard $X$. Thus, if $e_n$ is at the same shard as $e_1$, $e_n$ must arrive at shard $X$ after $e_n$ is \textit{committed} and \textit{coordinated}.

Using similar reasoning shown in lemma \ref{lemma2}, if $e_1$ is \textit{committed} and \textit{coordinated} and ordered in the shard log before $e_n$, then $\epsilon_1 < \epsilon_n$.

\noindentparagraph{Case 2.} \textit{With failures}.
Consider (the only interesting case) where shard $X$ fails after $e_1$ and $e_n$ have been \textit{committed} and \textit{coordinated} but not \textit{ordered}. We know that the new leader will contain both $e_1$ and $e_n$ in its set of committed-but-not-ordered entries since they were committed prior to failure and by the quorum intersection property, the new leader will have both of them. The new shard leader will call \texttt{getTimestampChain} for all committed-but-not-ordered entries, including $e_1$ and $e_n$.

It must be the case that $e_1$ had a successor since by construction it precedes another entry, $e_{n-1}$, which has executed and responded to a client. Moreover, since $e_{n-1}$ has executed and responded to its client, and this failover is happening after $e_{n-1}$ has executed and responded to its client, \texttt{getTimestampChain}$(e_1)$ will return a non-NULL value. Thus $e_1$ will be assigned its old timestamp from prior to failover and in the first set of entries processed in the failover protocol.

If $e_n$ receives a NULL value from its call to \texttt{getTimestampChain}, then it is trivially the case that $\epsilon_1 < \epsilon_n$, since it will be processed in the second set of entries, and its timestamp will be at least as large as the shard timestamp which is also strictly larger than the last timestamp assigned from the first set of entries processed during failover.

Otherwise, if $e_n$ receives a non-NULL value from its call to \texttt{getTimestampChain}, then it will be assigned whatever timestamp it had been assigned prior to failover. Since both $e_1$ and $e_n$ can retrieve their old timestamps and recycle them, this case turns into Case 1, where we have already shown this lemma holds.

% By the failover protocol, the new leader will first get the predecessor and successor timestamps for all committed-but-not-ordered entries, including $e_1$ and $e_n$, via calls made to \texttt{getPredecessor} and \texttt{getSuccessor}.

% As in Case 1 (\textit{No failures}), we know the old leader had assigned timestamps to $e_1$ and $e_n$ as
% $$\epsilon_1 = \max(e_{1\text{pred}} + 1, \text{shard\_ts}) = \max(e_{1\text{pred}} + 1, \text{shard\_ts}_0)$$
% $$\epsilon_n = \max(e_{1\text{pred}} + 1, \epsilon_1 + 1) \geq \epsilon_1 + 1 > \epsilon_1$$


% The values for $\epsilon_1$ and $\epsilon_n$ are also the values $e_1$ and $e_n$ would have sent to their successors prior to failover (if any existed). So we know if \texttt{getSuccessor} returns a non-infinity value for $e_1$ and $e_n$, they will be at least


% $$\epsilon_1\_\text{succ} > \epsilon_1 = \max(\epsilon_1\_\text{pred} + 1, \text{shard\_ts})$$
% $$\epsilon_n\_\text{succ} \geq \max(\epsilon_n\_\text{pred} + 1, \epsilon_1 + 1) \geq \epsilon_1 + 1$$

% We know $e_1$ had a successor since by construction it precedes another entry, $e_{n-1}$, which has executed and responded to a client. Moreover, since $e_{n-1}$ has executed and responded to its client, and this failover is happening after $e_{n-1}$ has executed and responded to its client, \texttt{getSuccessor}$(e_1)$ will return a non-infinity value $v_1 \geq \epsilon_1\_\text{succ}$.

% We don't know if $e_n$ had a successor. If it did not, \texttt{getSuccessor}($e_n$) will return infinity during failure recovery. If it did, it will return a value $v_n = \epsilon_n\_\text{succ} > \epsilon_n \geq \epsilon_1 + 1$.

% After obtaining the predecessor and successor timestamps, the new leader will sort all the committed-but-not-ordered entries by their successor timestamps, $\epsilon_i\_\text{succ}$. We know the following to be true about $e_1$ and $e_n$ after the sort completes:

% If $\epsilon_n\_\text{succ} = \infty$, then it is clear $e_1$ will be sorted before $e_n$. Otherwise, we also know 
% $$\texttt{getSuccessor}(e_1) = v_1 \geq \epsilon_1\_\text{succ} > \epsilon_1$$
% $$\texttt{getSuccessor}(e_n) = v_n \geq \epsilon_n\_\text{succ} > \epsilon_1 + 1$$
% Thus, $e_1$ will still be sorted before $e_n$.

% After the sort, we assign new monotonically increasing timestamps in sorted order, incrementing the shard timestamp between each assignment (as shown in previous lemmas), giving
% $\epsilon_n >= \max(\epsilon_n\_\text{pred} + 1, \epsilon_1 + 1)$
% or,
% $\epsilon_1 < \epsilon_n$
\end{proof}

\begin{lem}
\label{lemma5}
Consider 3 operations, $e_1, e_2, e_3$, such that $e_1 \rightarrow e_2 <_p e_3$. Then $e_1 \rightarrow e_3$.
\end{lem}
\begin{proof}
    If $e_1 \rightarrow e_2$, then by the definition of real time, $\text{resp}(e_1) < \text{inv}(e_2)$. Moreover, if $e_2 <_p e_3$, we also know by the definition of $<_p$ that $\text{inv}(e_2) < \text{inv}(e_3)$. Thus, we have $\text{resp}(e_1) < \text{inv}(e_3) < \text{inv}(e_3)$. But this gives us $e_1 \rightarrow e_3$.
\end{proof}

Let $<_\psi$ be a partial order defined over pairs of complete operations $e_1, e_2$, as follows:
\begin{enumerate}
    \item $e_1 <_x e_2 \implies e_1 <_\psi e_2$
    \item $e_1 <_p e_2 \implies e_1 <_\psi e_2$
    \item $e_1 \rightarrow e_2 \implies e_1 <_\psi e_2$, and
    \item $e_1 <_\psi e_2 \land e_2 <_\psi e_3 \implies e_1 <_\psi e_3$
\end{enumerate}

\begin{lem}
\label{lemmamain}
The partial order $<_\psi$ is acyclic.
\end{lem}
\begin{proof}
We prove the lemma by contradiction, assuming the partial order contains a cycle. Consider a minimum cycle of $n$ operations $e_1,e_2,...,e_n$. Observe that $<_\psi$ is irreflexive by definition, so $n \geq 2$. First, we prove three useful properties of the minimum cycle.

\noindentparagraph{Property 1.} \textit{The cycle contains no consecutive $<_p$ edges.} {Assume for the sake of contradiction there exist two consecutive $<_p$ edges $e_i <_p e_{i+1} <_p e_{i+2}$. By the transitivity of $<_p$, there exists a shorter edge $e_i <_p e_{i+2}$ which is part of the shorter cycle $..., e_i, e_{i+2}, ..., e_i$, a contradiction.}

\noindentparagraph{Property 2.} \textit{The cycle contains no consecutive $<_x$ edges.} {Using similar reasoning as in the above, $e_i <_x e_{i+1} <_x e_{i+2}$ would imply the existence of a shorter cycle that contains the edge $e_i <_x e_{i+2}$, a contradiction.}

\noindentparagraph{Property 3.} \textit{The cycle contains at most one $\rightarrow$ edge.} Assume for the sake of contradiction that the cycle contains two $\rightarrow$ edges, $e_i \rightarrow e_j .... e_k \rightarrow e_l$, where $i < j \leq k < l$, reindexing the cycle if necessary. From the definition of $\rightarrow$, we know $\resp(e_i) < \inv(e_j)$ and $\resp(e_k) < \inv(e_l)$. We also know $\inv(e_l) < \resp(e_i)$, otherwise a shorter cycle would exist containing the edge $e_i \rightarrow e_l$. Similarly, we also know $\inv(e_j) < \resp(e_k)$, otherwise a shorter cycle would exist containing the edge $e_k \rightarrow e_j$. We arrive at a contradiction, since $\resp(e_i) < \inv(e_j) < \resp(e_k) < \inv(e_l) < \resp(e_i)$, which gives $\resp(e_i) < \resp(e_i)$.

By Property 3, there are only two cases to consider:

\noindentparagraph{Case 1.} \textit{There are zero $\rightarrow$ edges in the minimum cycle.} Since $n \geq 2$, and by Properties 1 and 2, at least one edge is a $<_x$ edge and at least one edge is a $<_p$ edge. Also by properties 1 and 2, the cycle must alternate between $<_{x_i}$ and $<_{p_j}$ edges. 

Without loss of generality, re-index the cycle such that $e_1 <_{x_2} e_2 ... <_{p_1} e_1$. By repeated application of Lemmas~\ref{lemma1} and ~\ref{lemma2}, $\varepsilon_1 < \varepsilon_n$. But by Lemma~\ref{lemma2}, $\varepsilon_n < \varepsilon_1$, a contradiction.

\noindentparagraph{Case 2.} \textit{There is one $\rightarrow$ edge in the cycle.}

% Consider separately the cases where $n = 2$ and $n > 2$.

% If $n = 2$, without loss of generality, the cycle is of the form $e_1 <_p e_2 \rightarrow e_1$. By the definitions of $<_p$ and $\rightarrow$, we have $\text{inv}(e_1) < \text{inv}(e_2)$ and $\text{resp}(e_2) < \text{inv}(e_1)$. Since it must be true that $\text{inv}(e_2) < \text{resp}(e_2)$, we have $\text{inv}(e_1) < \text{inv}(e_1)$, a contradiction.

If $n \geq 2$, by Properties 1 and 2 at least one edge is a $<_x$ edge and at least one edge is a $<_p$ edge. Also by properties 1 and 2, the cycle must alternate between $n-1$ $<_{x_i}$ and $<_{p_j}$ edges, and include a single $\rightarrow$ edge. Moreover, by \ref{lemma5}, the edge following the $\rightarrow$ must be $<_x$, otherwise a shorter cycle would exist. 

Without loss of generality, re-index the cycle such that $e_1 ... e_{n-1} \rightarrow e_n <_x e_1$, where the edges between $e_1$ and $e_2$ alternate between $<_p$ and $<_x$, making no assumptions about which appears first. By lemma \ref{lemma3}, $\epsilon_1 < \epsilon_n$. But by lemma \ref{lemma2}, $\epsilon_n < \epsilon_1$, a contradiction.
\end{proof}


\begin{lem}
    \label{lemmaD14}
    A topological sort $S$ of $<_\psi$ over complete operations to objects $X$ is in the system sequential specification $\prod_{x \in X}\mathcal{G}_x$.
\end{lem}
\begin{proof}
    Since each operation targets a single object $x \in X$, it suffices to only consider the orders of subsets of operations to each $x$. For a fixed $x$, this order is solely dictated by the partial order $<_x$ in the topological sort of $<_\psi$. Lemma \ref{lemmaD8} shows that the sequence $S_x$ defined by $<_x$ is in $x$'s sequential specification $\mathcal{G}_x$. Since $S$ is a topological sort over $<_\psi$, which by definition generalizes each $<_x$, it follows that the entire sequence $S$ is in $\prod_{x \in X}\mathcal{G}_x$.
\end{proof}

\begin{thm}
    \sys{} guarantees \mdllong{}.
\end{thm}

\begin{proof}
    Let $\alpha_1$ be a well-formed execution of \sys{}. Extend $\alpha_1$ to $\alpha_2$ by adding a response action for any complete operation $e$ that does not have one in $\alpha_1$.

    Let $S$ be a topological sort of $<_\psi$ on the operations in $\alpha_2$. Lemma \ref{lemmaD14} implies that $S$ is in the system sequential specification. We now show that $S$ satisfies the two remaining properties of \mdllong{}, invocation and real time ordering.

    (1) Consider two operations $e_1$ and $e_2$ such that $e_1 <_p e_2$. By the definition of $<_\psi$, $e_1 <_\psi e_2$, and since $S$ is a topological sort of $<_\psi$, $e_1 <_S e_2$.
    
    (2) Consider two operations $e_1$ and $e_2$ such that $e_1 \rightarrow e_2$. By the definition of $<_\psi$, $e_1 <_\psi e_2$, and since $S$ is a topological sort of $<_\psi$, $e_1 <_S e_2$.
\end{proof}